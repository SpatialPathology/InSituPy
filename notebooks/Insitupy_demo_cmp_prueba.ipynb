{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import warnings\n",
    "from typing import List, Literal, Optional\n",
    "from anndata import AnnData\n",
    "from insitupy.utils.preprocessing import sctransform_anndata\n",
    "from pathlib import Path\n",
    "from insitupy.datasets.download import download_url\n",
    "import shutil\n",
    "import os\n",
    "from insitupy import read_xenium\n",
    "import scanpy as sc\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"demo_dataset\") # output directory\n",
    "data_dir = out_dir / \"output-XETG00000__0001879__Replicate 1\" # directory of xenium data\n",
    "image_dir = out_dir / \"unregistered_images\" # directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"demo_dataset\") # output directory\n",
    "data_dir = out_dir / \"output-XETG00000__0001879__Replicate 1\" # directory of xenium data\n",
    "image_dir = out_dir / \"unregistered_images\" # directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = read_xenium(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_transformations_anndata(\n",
    "    adata: AnnData,\n",
    "    transformation_methods: List[Literal[\"log1p\", \"sqrt_1\", \"sqrt_2\", \"pearson_residuals\", \"sctransform\"]],\n",
    "    verbose: bool = True,\n",
    "    output_path: str = \"normalization_results.html\",\n",
    "    true_labels: Optional[pd.Series] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize and transform the data in an AnnData object based on specified methods,\n",
    "    and then compare the transformed results using various metrics.\n",
    "\n",
    "    Args:\n",
    "        adata (AnnData): The AnnData object to be normalized and transformed.\n",
    "        transformation_methods (List[str]): List of transformation methods to apply.\n",
    "            Options are [\"log1p\", \"sqrt_1\", \"sqrt_2\", \"pearson_residuals\", \"sctransform\"].\n",
    "        verbose (bool, optional): If True, prints progress messages. Default is True.\n",
    "        output_path (str, optional): The path where the HTML report will be saved.\n",
    "            Default is 'normalization_results.html'.\n",
    "        true_labels (Optional[pd.Series], optional): True labels for the cells,\n",
    "            if available, for computing ARI.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with comparison metrics for each transformation method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Import necessary libraries\n",
    "    import scanpy as sc\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "    from sklearn.cluster import KMeans\n",
    "    from scipy.stats import zscore\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from io import BytesIO\n",
    "    import base64\n",
    "    import warnings\n",
    "\n",
    "    # Suppress warnings for cleaner output\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Step 1: Normalize and transform the data using the specified methods\n",
    "    if verbose:\n",
    "        print(\"Storing raw counts in adata.layers['counts']...\")\n",
    "\n",
    "    # Store raw counts for comparison\n",
    "    adata.layers['counts'] = adata.X.copy()\n",
    "\n",
    "    # Normalize total counts\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    adata.layers['norm_counts'] = adata.X.copy()\n",
    "\n",
    "    # Dictionary to store different transformations\n",
    "    transformed_data = {}\n",
    "\n",
    "    for method in transformation_methods:\n",
    "        if verbose:\n",
    "            print(f\"Applying transformation: {method}\")\n",
    "\n",
    "        # Copy the normalized AnnData object for each transformation\n",
    "        adata_copy = adata.copy()\n",
    "\n",
    "        # Apply the selected transformation method\n",
    "        if method == \"log1p\":\n",
    "            sc.pp.log1p(adata_copy)\n",
    "\n",
    "        elif method == \"sqrt_1\":\n",
    "            X = adata_copy.X.toarray()\n",
    "            adata_copy.X = csr_matrix(np.sqrt(X + 1))\n",
    "\n",
    "        elif method == \"sqrt_2\":\n",
    "            X = adata_copy.X.toarray()\n",
    "            adata_copy.X = csr_matrix(np.sqrt(X))\n",
    "\n",
    "        elif method == \"pearson_residuals\":\n",
    "            # Applying the Pearson residuals transformation\n",
    "            sc.experimental.pp.normalize_pearson_residuals(adata_copy, layer=\"counts\", inplace=True)\n",
    "\n",
    "        elif method == \"sctransform\":\n",
    "            # Applying SCTransform using your custom function\n",
    "            adata_copy = sctransform_anndata(adata_copy)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'`transformation_method` {method} is not valid.')\n",
    "\n",
    "        # Store the transformed AnnData object in the results dictionary\n",
    "        transformed_data[method] = adata_copy\n",
    "\n",
    "    # Step 2: Compare the transformations and generate the plots\n",
    "    results = {}\n",
    "    plots = []\n",
    "\n",
    "\n",
    "    for method, transformed_adata in transformed_data.items():\n",
    "        if verbose:\n",
    "            print(f\"Processing {method}...\")\n",
    "\n",
    "        # Compute PCA for dimensionality reduction\n",
    "        sc.pp.pca(transformed_adata, n_comps=10)\n",
    "        X_pca = transformed_adata.obsm['X_pca']\n",
    "\n",
    "        # Clustering with KMeans\n",
    "        kmeans = KMeans(n_clusters=5, random_state=0).fit(X_pca)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # Compute Silhouette Score\n",
    "        sil_score = silhouette_score(X_pca, labels)\n",
    "\n",
    "        # Mean-Variance Relationship\n",
    "        X_array = transformed_adata.X.toarray()\n",
    "        mean_expression = np.mean(X_array, axis=0)\n",
    "        variance_expression = np.var(X_array, axis=0)\n",
    "        variance_stabilization = np.corrcoef(mean_expression, variance_expression)[0, 1]\n",
    "\n",
    "        # Z-Score Mean\n",
    "        z_scores = zscore(X_array, axis=0, ddof=1)\n",
    "        z_score_mean = np.nanmean(z_scores)\n",
    "\n",
    "        # Coefficient of Variation (CV)\n",
    "        cv = np.std(X_array) / np.mean(X_array)\n",
    "\n",
    "        # Adjusted Rand Index (ARI)\n",
    "        if true_labels is not None:\n",
    "            ari = adjusted_rand_score(true_labels, labels)\n",
    "        else:\n",
    "            ari = np.nan\n",
    "\n",
    "        # Store results for comparison\n",
    "        results[method] = {\n",
    "            \"Silhouette Score\": sil_score,\n",
    "            \"Variance Stabilization\": variance_stabilization,\n",
    "            \"Z-Score Mean\": z_score_mean,\n",
    "            \"Coefficient of Variation\": cv,\n",
    "            \"Adjusted Rand Index\": ari\n",
    "        }\n",
    "\n",
    "        # Generate Mean-Variance Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(mean_expression, variance_expression, alpha=0.5, s=10)\n",
    "        plt.xlabel('Mean Expression')\n",
    "        plt.ylabel('Variance')\n",
    "        plt.title(f'Mean-Variance Plot - {method}')\n",
    "        plt.tight_layout()\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "        plots.append(f'<h3>{method} - Mean-Variance Plot</h3><img src=\"data:image/png;base64,{image_base64}\" alt=\"{method} Mean-Variance Plot\"/>')\n",
    "\n",
    "    # Convert results dictionary to a DataFrame for easier comparison\n",
    "    results_df = pd.DataFrame(results).T  # Transpose to have methods as rows\n",
    "\n",
    "    # Highlight the best methods and create HTML table\n",
    "    def highlight_best_method(results_df):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        highlighted_df = results_df.copy()\n",
    "\n",
    "        # For metrics where higher is better\n",
    "        metrics_to_maximize = ['Silhouette Score', 'Adjusted Rand Index']\n",
    "\n",
    "        # For metrics where lower is better\n",
    "        metrics_to_minimize = ['Variance Stabilization', 'Z-Score Mean', 'Coefficient of Variation']\n",
    "\n",
    "        # Highlight the best values\n",
    "        for metric in metrics_to_maximize:\n",
    "            if metric in highlighted_df.columns:\n",
    "                best_value_index = highlighted_df[metric].idxmax()\n",
    "                highlighted_df.loc[best_value_index, metric] = (\n",
    "                    f'<div style=\"background-color:lightgreen\">{results_df.loc[best_value_index, metric]}</div>'\n",
    "                )\n",
    "\n",
    "        for metric in metrics_to_minimize:\n",
    "            if metric in highlighted_df.columns:\n",
    "                best_value_index = highlighted_df[metric].abs().idxmin()\n",
    "                highlighted_df.loc[best_value_index, metric] = (\n",
    "                    f'<div style=\"background-color:lightgreen\">{results_df.loc[best_value_index, metric]}</div>'\n",
    "                )\n",
    "\n",
    "        # Convert the DataFrame to HTML with escape=False to allow HTML tags\n",
    "        return highlighted_df.to_html(escape=False)\n",
    "\n",
    "    results_html = highlight_best_method(results_df)\n",
    "\n",
    "    # Generate the final HTML report\n",
    "    full_html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Transformation Results</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Transformation Comparison Results</h1>\n",
    "        <h2>Summary Table</h2>\n",
    "        {results_html}\n",
    "        <h2>Transformation Method Plots</h2>\n",
    "        {\"<br>\".join(plots)}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the HTML file to the specified output path\n",
    "    with open(output_path, \"w\") as file:\n",
    "        file.write(full_html)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"HTML report created and saved as '{output_path}'\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cells...\n"
     ]
    }
   ],
   "source": [
    "xd.load_cells()\n",
    "adata = xd.cells.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing raw counts in adata.layers['counts']...\n",
      "Applying transformation: log1p\n",
      "Applying transformation: sqrt_1\n",
      "Applying transformation: sqrt_2\n",
      "Applying transformation: pearson_residuals\n",
      "Applying transformation: sctransform\n",
      "Starting SCTransform...\n",
      "AnnData object saved temporarily at: C:\\Users\\Aitana\\AppData\\Local\\Temp\\tmp2cpcoxh9.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Running SCTransform on assay: RNA\n",
      "\n",
      "R[write to console]: vst.flavor='v2' set. Using model with fixed slope and excluding poisson genes.\n",
      "\n",
      "R[write to console]: Calculating cell attributes from input UMI matrix: log_umi\n",
      "\n",
      "R[write to console]: Variance stabilizing transformation of count matrix of size 313 by 166363\n",
      "\n",
      "R[write to console]: Model formula is y ~ log_umi\n",
      "\n",
      "R[write to console]: Get Negative Binomial regression parameters per gene\n",
      "\n",
      "R[write to console]: Using 312 genes, 5000 cells\n",
      "\n",
      "R[write to console]: Second step: Get residuals using fitted parameters for 313 genes\n",
      "\n",
      "R[write to console]: Computing corrected count matrix for 313 genes\n",
      "\n",
      "R[write to console]: Calculating gene attributes\n",
      "\n",
      "R[write to console]: Wall clock passed: Time difference of 18.82202 secs\n",
      "\n",
      "R[write to console]: Determine variable features\n",
      "\n",
      "R[write to console]: Centering data matrix\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Place corrected count matrix in counts slot\n",
      "\n",
      "R[write to console]: Set default assay to SCT\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCTransform applied to Seurat object.\n",
      "Converted Seurat object to SingleCellExperiment.\n",
      "SCTransform transformation completed and returned as AnnData.\n",
      "Processing log1p...\n",
      "Processing sqrt_1...\n",
      "Processing sqrt_2...\n",
      "Processing pearson_residuals...\n",
      "Processing sctransform...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Aitana\\Anaconda3\\envs\\insitupy\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: nan",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_transformations_anndata\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformation_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog1p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqrt_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msqrt_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpearson_residuals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msctransform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 183\u001b[0m, in \u001b[0;36mcompare_transformations_anndata\u001b[1;34m(adata, transformation_methods, verbose, output_path, true_labels)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# Convert the DataFrame to HTML with escape=False to allow HTML tags\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m highlighted_df\u001b[38;5;241m.\u001b[39mto_html(escape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 183\u001b[0m results_html \u001b[38;5;241m=\u001b[39m \u001b[43mhighlight_best_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Generate the final HTML report\u001b[39;00m\n\u001b[0;32m    186\u001b[0m full_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124m<html>\u001b[39m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124m<head>\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124m</html>\u001b[39m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[13], line 170\u001b[0m, in \u001b[0;36mcompare_transformations_anndata.<locals>.highlight_best_method\u001b[1;34m(results_df)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m highlighted_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m    168\u001b[0m         best_value_index \u001b[38;5;241m=\u001b[39m highlighted_df[metric]\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m    169\u001b[0m         highlighted_df\u001b[38;5;241m.\u001b[39mloc[best_value_index, metric] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 170\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<div style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackground-color:lightgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_df\u001b[38;5;241m.\u001b[39mloc[best_value_index,\u001b[38;5;250m \u001b[39mmetric]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</div>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    171\u001b[0m         )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics_to_minimize:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m highlighted_df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\Aitana\\Anaconda3\\envs\\insitupy\\lib\\site-packages\\pandas\\core\\indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aitana\\Anaconda3\\envs\\insitupy\\lib\\site-packages\\pandas\\core\\frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aitana\\Anaconda3\\envs\\insitupy\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "compare_transformations_anndata(adata, transformation_methods=[\"log1p\", \"sqrt_1\", \"sqrt_2\", \"pearson_residuals\", \"sctransform\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (insitupy)",
   "language": "python",
   "name": "insitupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
